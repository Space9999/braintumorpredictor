{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1P8gQMnkNM9FtXCt8RVQpcGFVcDW01dPz",
      "authorship_tag": "ABX9TyMux3JXPaMFM+Op9D1P6V3f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Space9999/braintumorpredictor/blob/main/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import pandas as pd\n",
        "import cv2\n",
        "sns.set()"
      ],
      "metadata": {
        "id": "G4BJ-ZLka-UC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ctHealthyPath = glob.glob(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Images/Dataset/Brain Tumor CT scan Images\", \"Healthy\", \"*.jpg\"))\n",
        "ctTumorPath  = glob.glob(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Images/Dataset/Brain Tumor CT scan Images\", \"Tumor\", \"*.jpg\"))\n",
        "mriHealthyPath = glob.glob(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Images/Dataset/Brain Tumor MRI images\", \"Healthy\", \"*.jpg\"))\n",
        "mriTumorPath  = glob.glob(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Images/Dataset/Brain Tumor MRI images\", \"Tumor\", \"*.jpg\"))\n",
        "data = []\n",
        "\n",
        "for path in ctHealthyPath:\n",
        "    data.append((path, 0, \"CT\"))\n",
        "for path in ctTumorPath:\n",
        "    data.append((path, 1, \"CT\"))\n",
        "\n",
        "for path in mriHealthyPath:\n",
        "    data.append((path, 0, \"MRI\"))\n",
        "for path in mriTumorPath:\n",
        "    data.append((path, 1, \"MRI\"))\n",
        "\n",
        "print(\"Number of Data entries:\")\n",
        "print(\"CT Healthy: \", len(ctHealthyPath))\n",
        "print(\"CT Tumor: \", len(ctTumorPath))\n",
        "print(\"MRI Healthy: \", len(mriHealthyPath))\n",
        "print(\"MRI Tumor: \", len(mriTumorPath))\n",
        "print(\"Total images in Data:\", len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_ZmXOAhbte7",
        "outputId": "8b6d0c12-113b-47e9-cd67-5e309cf2b599"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Data entries:\n",
            "CT Healthy:  1613\n",
            "CT Tumor:  2054\n",
            "MRI Healthy:  1849\n",
            "MRI Tumor:  2784\n",
            "Total images in Data: 8300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [i[1] for i in data]\n",
        "train_paths, val_paths, train_labels, val_labels = train_test_split(data, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "FfA5G98tk-Bw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1.0/255)"
      ],
      "metadata": {
        "id": "xa8m2Igcl_Hx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(image_paths, labels, batch_size=32, target_size=(224, 224)):\n",
        "    # Ensure the generator always yields something, even if there are no images\n",
        "    if not image_paths:  # If image_paths is empty\n",
        "        yield np.empty((0, *target_size, 3)), np.empty((0,))  # yield empty arrays\n",
        "    else:\n",
        "        while True:\n",
        "            for i in range(0, len(image_paths), batch_size):\n",
        "                batch_paths = image_paths[i:i + batch_size]\n",
        "                batch_labels = labels[i:i + batch_size]\n",
        "\n",
        "                images = []\n",
        "                for img_data in batch_paths:\n",
        "                    img_path = img_data[0]\n",
        "                    img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
        "                    img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "                    images.append(img)\n",
        "\n",
        "                images = np.array(images)\n",
        "                yield images, np.array(batch_labels)\n",
        "train_generator = generate_images(train_paths, train_labels, batch_size=32)\n",
        "val_generator = generate_images(val_paths, val_labels, batch_size=32)"
      ],
      "metadata": {
        "id": "0vmLY83UmO-Y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetV2B0\n",
        "base_model = EfficientNetV2B0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "#  Fine-Tuning\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)  # one output (tumor / healthy)\n",
        "\n",
        "# bulid the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# while training , trainable = false\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_paths) // 32,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(val_paths) // 32,\n",
        "    epochs=7\n",
        ")"
      ],
      "metadata": {
        "id": "RZSzU_qI01h5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00427e2e-b8c1-467d-a01d-cc5d783e8cfe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m597s\u001b[0m 3s/step - accuracy: 0.9084 - loss: 0.2096 - val_accuracy: 0.9724 - val_loss: 0.0856\n",
            "Epoch 2/7\n",
            "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 3s/step - accuracy: 0.9795 - loss: 0.0616 - val_accuracy: 0.9822 - val_loss: 0.0591\n",
            "Epoch 3/7\n",
            "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 3s/step - accuracy: 0.9848 - loss: 0.0405 - val_accuracy: 0.9840 - val_loss: 0.0545\n",
            "Epoch 4/7\n",
            "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 3s/step - accuracy: 0.9890 - loss: 0.0305 - val_accuracy: 0.9834 - val_loss: 0.0471\n",
            "Epoch 5/7\n",
            "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 3s/step - accuracy: 0.9908 - loss: 0.0277 - val_accuracy: 0.9760 - val_loss: 0.0664\n",
            "Epoch 6/7\n",
            "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m545s\u001b[0m 3s/step - accuracy: 0.9887 - loss: 0.0267 - val_accuracy: 0.9883 - val_loss: 0.0349\n",
            "Epoch 7/7\n",
            "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 3s/step - accuracy: 0.9925 - loss: 0.0190 - val_accuracy: 0.9859 - val_loss: 0.0518\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x799b83636fb0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_accuracy = model.evaluate(val_generator, steps=len(val_paths) // 32)\n",
        "print(f\"Validation Loss: {val_loss}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egD2sjF8LmJu",
        "outputId": "00174f56-2fb0-489c-f489-a8775caf153f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2s/step - accuracy: 0.9856 - loss: 0.0603\n",
            "Validation Loss: 0.05177828297019005\n",
            "Validation Accuracy: 0.985872209072113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model2.keras\")"
      ],
      "metadata": {
        "id": "AMGeLGMbgK2a"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ctHealthyPathVal = glob.glob(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Images/Dataset\", \"CT_HealthyTest\", \"*.jpg\"))\n",
        "ctTumorPathVal  = glob.glob(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Images/Dataset\", \"CT_TumorTest\", \"*.jpg\"))\n",
        "mriHealthyPathVal = glob.glob(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Images/Dataset\", \"MRI_HealthyTest\", \"*.jpg\"))\n",
        "mriTumorPathVal  = glob.glob(os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Images/Dataset\", \"MRI_TumorTest\", \"*.jpg\"))\n",
        "\n",
        "testData = []\n",
        "\n",
        "for path in ctHealthyPathVal:\n",
        "    testData.append((path, 0, \"CT\"))\n",
        "for path in ctTumorPathVal:\n",
        "    testData.append((path, 1, \"CT\"))\n",
        "\n",
        "for path in mriHealthyPathVal:\n",
        "    testData.append((path, 0, \"MRI\"))\n",
        "for path in mriTumorPathVal:\n",
        "    testData.append((path, 1, \"MRI\"))\n",
        "\n",
        "print(\"Number of Test Data entries:\")\n",
        "print(\"CT Healthy: \", len(ctHealthyPathVal))\n",
        "print(\"CT Tumor: \", len(ctTumorPathVal))\n",
        "print(\"MRI Healthy: \", len(mriHealthyPathVal))\n",
        "print(\"MRI Tumor: \", len(mriTumorPathVal))\n",
        "print(\"Total images in Test Data:\", len(testData))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15wIBFzQgqYC",
        "outputId": "a8a773d0-8fd7-4d2c-ce3f-bacbb0e6aeb6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Test Data entries:\n",
            "CT Healthy:  103\n",
            "CT Tumor:  103\n",
            "MRI Healthy:  148\n",
            "MRI Tumor:  200\n",
            "Total images in Test Data: 554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_datagen_2 = ImageDataGenerator(rescale=1.0/255)"
      ],
      "metadata": {
        "id": "fu6NSUzPjDFp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(image_paths, labels, batch_size=32, target_size=(224, 224)):\n",
        "    # Ensure the generator always yields something, even if there are no images\n",
        "    if not image_paths:  # If image_paths is empty\n",
        "        yield np.empty((0, *target_size, 3)), np.empty((0,))  # yield empty arrays\n",
        "    else:\n",
        "        while True:\n",
        "            for i in range(0, len(image_paths), batch_size):\n",
        "                batch_paths = image_paths[i:i + batch_size]\n",
        "                batch_labels = labels[i:i + batch_size]\n",
        "\n",
        "                images = []\n",
        "                for img_data in batch_paths:\n",
        "                    img_path = img_data[0]\n",
        "                    img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
        "                    img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "                    images.append(img)\n",
        "\n",
        "                images = np.array(images)\n",
        "                yield images, np.array(batch_labels)\n",
        "testLabels = [j[1] for j in testData]\n",
        "val_generator = generate_images(testData, testLabels, batch_size=32)"
      ],
      "metadata": {
        "id": "TJx5AT91joHM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_accuracy = model.evaluate(val_generator, steps=len(testData) // 4)\n",
        "print(f\"Validation Loss: {val_loss}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WXCjYYbkewP",
        "outputId": "3c843fdc-371f-4684-93de-8f5a5956df21"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 2s/step - accuracy: 0.9198 - loss: 0.3150\n",
            "Validation Loss: 0.25208625197410583\n",
            "Validation Accuracy: 0.9343031644821167\n"
          ]
        }
      ]
    }
  ]
}